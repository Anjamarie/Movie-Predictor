{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2244aa0-c397-4a02-b635-5bc5811e2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import ast\n",
    "import streamlit as st\n",
    "import tmdbsimple as tmdb\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4391a9-3174-4136-a156-d444f5f4b0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 200 movies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Pages: 100%|███████████████████████████| 10/10 [01:06<00:00,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully fetched and processed data for 93 movies.\n",
      "\n",
      "Final training dataset size (Streamlit features only): (93, 15)\n",
      "\n",
      "Training final Streamlit-compatible model...\n",
      "\n",
      "---------------------------------------------------------\n",
      "SUCCESS: New model files generated locally.\n",
      "Saved Model Features (model_features.pkl):\n",
      "['budget', 'runtime', 'release_year', 'release_month', 'release_dayofweek', 'genre_Action', 'genre_Adventure', 'genre_Fantasy', 'genre_Thriller', 'genre_Science Fiction', 'genre_Family', 'genre_Animation', 'genre_Comedy', 'genre_Horror', 'genre_Drama']\n",
      "---------------------------------------------------------\n",
      "NEXT STEP: UPLOAD both 'movie_revenue_model.pkl' and 'model_features.pkl'\n",
      "to your Hugging Face repository, overwriting the old files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------\n",
    "# 1. Configuration (MUST BE SECURE if running outside local environment)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# NOTE: API_KEY is exposed here. For production, use environment variables.\n",
    "tmdb.API_KEY = '7eb2f50ca573c609c0bac8e9f804514d'\n",
    "\n",
    "PAGES_TO_FETCH = 10  # Reduced pages for quick test generation\n",
    "\n",
    "# Define the features that the Streamlit app actually collects from the user.\n",
    "STREAMLIT_INPUT_FEATURES = [\n",
    "    'budget',\n",
    "    'runtime',\n",
    "    'release_year',\n",
    "    'release_month',\n",
    "    'release_dayofweek',\n",
    "]\n",
    "# Genres will be added dynamically later\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Data Acquisition Function (Copied from Notebook)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def get_movie_data(movie_id):\n",
    "    \"\"\"Fetches detailed data for a single movie from TMDb.\"\"\"\n",
    "    try:\n",
    "        movie = tmdb.Movies(movie_id)\n",
    "        info = movie.info()\n",
    "        credits = movie.credits()\n",
    "        keywords = movie.keywords()\n",
    "        \n",
    "        director = next((person['name'] for person in credits['crew'] if person['job'] == 'Director'), None)\n",
    "        cast = [actor['name'] for actor in credits['cast'][:5]]\n",
    "        \n",
    "        # Filter for quality data before returning\n",
    "        if info.get('budget', 0) == 0 or info.get('revenue', 0) == 0:\n",
    "            return None\n",
    "        return {\n",
    "            'id': info['id'],\n",
    "            'title': info['title'],\n",
    "            'release_date': info.get('release_date'),\n",
    "            'budget': info.get('budget'),\n",
    "            'revenue': info.get('revenue'),\n",
    "            'runtime': info.get('runtime'),\n",
    "            'genres': [genre['name'] for genre in info.get('genres', [])],\n",
    "            'cast': cast,\n",
    "            'director': director,\n",
    "            'keywords': [keyword['name'] for keyword in keywords.get('keywords', [])],\n",
    "            'production_companies': [company['name'] for company in info.get('production_companies', [])[:5]]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Fetch Data (Reduced Pages for Quicker Local Run)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(f\"Fetching data for {PAGES_TO_FETCH * 20} movies...\")\n",
    "all_movie_data = []\n",
    "\n",
    "for page in tqdm(range(1, PAGES_TO_FETCH + 1), desc=\"Fetching Pages\"):\n",
    "    try:\n",
    "        discover = tmdb.Discover()\n",
    "        response = discover.movie(page=page, sort_by='popularity.desc')\n",
    "        \n",
    "        page_movie_ids = [movie['id'] for movie in response['results']]\n",
    "        \n",
    "        for movie_id in page_movie_ids:\n",
    "            data = get_movie_data(movie_id)\n",
    "            if data:\n",
    "                all_movie_data.append(data)\n",
    "            time.sleep(0.05) \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "df = pd.DataFrame(all_movie_data)\n",
    "print(f\"\\nSuccessfully fetched and processed data for {len(df)} movies.\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Feature Engineering (Simplified for Streamlit Inputs)\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Convert release_date and extract date features\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "df['release_month'] = df['release_date'].dt.month\n",
    "df['release_dayofweek'] = df['release_date'].dt.dayofweek\n",
    "\n",
    "# Drop rows where release_date failed conversion (NaNs)\n",
    "df.dropna(subset=['release_year'], inplace=True)\n",
    "\n",
    "# Engineer Genre Features (Matching the app.py multiselect logic)\n",
    "# Note: We need the list of genres used in the notebook to be consistent with the app.\n",
    "top_genres = df['genres'].explode().value_counts().nlargest(10).index\n",
    "for genre in top_genres:\n",
    "    df[f'genre_{genre}'] = df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
    "\n",
    "# Add the new genre dummy features to the list of expected Streamlit features\n",
    "STREAMLIT_INPUT_FEATURES.extend([f'genre_{g}' for g in top_genres])\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. Prep Data and Train the Streamlit-Compatible Model\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "y = df['revenue']\n",
    "X = df[STREAMLIT_INPUT_FEATURES].copy() # CRITICAL: Only use the simple input features\n",
    "\n",
    "# Final check for NaNs in X before training\n",
    "X.dropna(inplace=True)\n",
    "y = y[X.index] # Align y with cleaned X\n",
    "\n",
    "print(f\"\\nFinal training dataset size (Streamlit features only): {X.shape}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "# Use the best parameters found in your original notebook (0.05, max_depth: 5, n_estimators: 100)\n",
    "best_params = {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}\n",
    "gbr_final_for_app = GradientBoostingRegressor(**best_params, random_state=11)\n",
    "\n",
    "print(\"\\nTraining final Streamlit-compatible model...\")\n",
    "gbr_final_for_app.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Save the Final Model and Feature List\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# 1. Save the trained model object\n",
    "joblib.dump(gbr_final_for_app, 'movie_revenue_model.pkl')\n",
    "\n",
    "# 2. Save ONLY the list of feature names the Streamlit app must provide\n",
    "joblib.dump(X.columns.tolist(), 'model_features.pkl')\n",
    "\n",
    "print(\"\\n---------------------------------------------------------\")\n",
    "print(\"SUCCESS: New model files generated locally.\")\n",
    "print(\"Saved Model Features (model_features.pkl):\")\n",
    "print(X.columns.tolist())\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"NEXT STEP: UPLOAD both 'movie_revenue_model.pkl' and 'model_features.pkl'\")\n",
    "print(\"to your Hugging Face repository, overwriting the old files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef5d2e-d07c-4d8d-98da-af3e68da79f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
